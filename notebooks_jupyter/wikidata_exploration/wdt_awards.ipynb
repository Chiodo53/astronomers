{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awards\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Librairie à installer dans l'environnement conda (si on exécute en local)\n",
    "# qui sera choisi pour exécuter le carnet\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, TURTLE, XML, RDFXML\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Librairies déjà installées avec Python\n",
    "import pprint\n",
    "import csv\n",
    "\n",
    "import sqlite3 as sql\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "from shutil import copyfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importer un module de fonctions crées ad hoc\n",
    "##  ATTENTION : le fichier 'sparql_functions.py' doit se trouver \n",
    "#   dans un dossier qui se situe dans le chemin ('path') de recherche\n",
    "#   vu par le présent carnet Jupyter afin que\n",
    "#   l'importation fonctionne correctement\n",
    "\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "# Add parent directory to the path\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "### If you want to add the parent-parent directory,\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "\n",
    "import sparql_functions as spqf\n",
    "import network_analysis_functions as naf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mreload\u001b[49m(naf))  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'reload' is not defined"
     ]
    }
   ],
   "source": [
    "print(reload(naf))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data from the triplestore\n",
    "\n",
    "This notebook is based on the \n",
    "\n",
    "...  [compléter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define SPARQL enpoint\n",
    "endpoint = \"https://ag16gm9pr0meths2.allegrograph.cloud/repositories/astronomers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "PREFIX bd: <http://www.bigdata.com/rdf#>\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "\n",
    "SELECT ?person (MIN(?pLabel) AS ?personLabel)\n",
    "        (MIN(?birthYear) AS ?birthYear)\n",
    "      ?award (MIN(?aLabel) AS ?awardLabel)         \n",
    "   (COUNT(*) as ?n)\n",
    "   (GROUP_CONCAT(DISTINCT ?organisationLabel; separator=\" | \") AS ?organisations) \n",
    "   (GROUP_CONCAT(DISTINCT ?parentTermLabel; separator=\" | \") AS ?domains) \n",
    "   (GROUP_CONCAT(DISTINCT ?countryLabel; separator=\" | \") AS ?countries) \n",
    "   (GROUP_CONCAT(DISTINCT ?pseudoClassLabel; separator=\" | \") AS ?pseudoClasses) \n",
    "     \n",
    "WHERE {\n",
    "      GRAPH <https://github.com/Sciences-historiques-numeriques/astronomers/blob/main/graphs/wikidata-imported-data.md>\n",
    "         {\n",
    "            ?person wdt:P166 ?award;\n",
    "                     rdfs:label ?pLabel;\n",
    "                     wdt:P569 ?birthYear.\n",
    "            ?award rdf:type wd:Q618779;\n",
    "                  rdfs:label ?aLabel.\n",
    "            # has country      \n",
    "            OPTIONAL {?award wdt:P17 ?country.\n",
    "                ?country rdfs:label ?countryLabel    \n",
    "             }\n",
    "            #  instance of\n",
    "            OPTIONAL {?award wdt:P31 ?pseudoClass.\n",
    "                ?pseudoClass rdfs:label ?pseudoClassLabel    \n",
    "             }\n",
    "            # conferred by\n",
    "            OPTIONAL {?award wdt:P1027 ?organisation.\n",
    "                ?organisation rdfs:label ?organisationLabel    \n",
    "             }  \n",
    "            # subclass of\n",
    "            OPTIONAL \n",
    "            {?award wdt:P279 ?parentTerm.\n",
    "                ?parentTerm rdfs:label ?parentTermLabel    \n",
    "             }   \n",
    "\n",
    "         }\n",
    "   }\n",
    "GROUP BY ?person ?award \n",
    "ORDER BY DESC(?domains)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35122\n",
      "[['http://www.wikidata.org/entity/Q1819421',\n",
      "  'Leonid Keldysh',\n",
      "  '1931',\n",
      "  'http://www.wikidata.org/entity/Q1400970',\n",
      "  'Feenberg Medal',\n",
      "  '1',\n",
      "  '',\n",
      "  'science award',\n",
      "  '',\n",
      "  ''],\n",
      " ['http://www.wikidata.org/entity/Q1699823',\n",
      "  'John Dirk Walecka',\n",
      "  '1932',\n",
      "  'http://www.wikidata.org/entity/Q1400970',\n",
      "  'Feenberg Medal',\n",
      "  '1',\n",
      "  '',\n",
      "  'science award',\n",
      "  '',\n",
      "  ''],\n",
      " ['http://www.wikidata.org/entity/Q111270596',\n",
      "  'László Csaba',\n",
      "  '1935',\n",
      "  'http://www.wikidata.org/entity/Q1301832',\n",
      "  'Széchenyi Prize',\n",
      "  '1',\n",
      "  '',\n",
      "  'science award',\n",
      "  'Hungary',\n",
      "  'science award']]\n"
     ]
    }
   ],
   "source": [
    "### Executer la requête avec les fonctions de la librairie locale\n",
    "try:\n",
    "    qr = spqf.get_json_sparql_result(endpoint,query)\n",
    "    out = [l for l in spqf.sparql_result_to_list(qr)]\n",
    "    print(len(out))\n",
    "    pprint.pprint(out[100:103])\n",
    "except Exception as e:\n",
    "    print(e)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q20507722</td>\n",
       "      <td>Q20507722</td>\n",
       "      <td>1949</td>\n",
       "      <td>http://www.wikidata.org/entity/Q121594</td>\n",
       "      <td>professor</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>university teacher | research fellow</td>\n",
       "      <td></td>\n",
       "      <td>title of authority | style | academic rank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0          1     2  \\\n",
       "0  http://www.wikidata.org/entity/Q20507722  Q20507722  1949   \n",
       "\n",
       "                                        3          4  5 6  \\\n",
       "0  http://www.wikidata.org/entity/Q121594  professor  6     \n",
       "\n",
       "                                      7 8  \\\n",
       "0  university teacher | research fellow     \n",
       "\n",
       "                                            9  \n",
       "0  title of authority | style | academic rank  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Créer un DataFrame à partir du résultat\n",
    "df_p = pd.DataFrame(out)\n",
    "df_p.head(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number:  35122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uriPer</th>\n",
       "      <th>labelPer</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>uriAw</th>\n",
       "      <th>labelAw</th>\n",
       "      <th>number</th>\n",
       "      <th>organisations</th>\n",
       "      <th>domains</th>\n",
       "      <th>countries</th>\n",
       "      <th>pseudoClasses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1291839</td>\n",
       "      <td>Edward C. Stone</td>\n",
       "      <td>1936</td>\n",
       "      <td>http://www.wikidata.org/entity/Q209896</td>\n",
       "      <td>honorary degree</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>title of honor | academic degree</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>http://www.wikidata.org/entity/Q5479986</td>\n",
       "      <td>Francis Allotey</td>\n",
       "      <td>1932</td>\n",
       "      <td>http://www.wikidata.org/entity/Q209896</td>\n",
       "      <td>honorary degree</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>title of honor | academic degree</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>http://www.wikidata.org/entity/Q4258994</td>\n",
       "      <td>Aleksandr Leontyev</td>\n",
       "      <td>1927</td>\n",
       "      <td>http://www.wikidata.org/entity/Q209896</td>\n",
       "      <td>honorary degree</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>title of honor | academic degree</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     uriPer            labelPer birthYear  \\\n",
       "10  http://www.wikidata.org/entity/Q1291839     Edward C. Stone      1936   \n",
       "11  http://www.wikidata.org/entity/Q5479986     Francis Allotey      1932   \n",
       "12  http://www.wikidata.org/entity/Q4258994  Aleksandr Leontyev      1927   \n",
       "\n",
       "                                     uriAw          labelAw number  \\\n",
       "10  http://www.wikidata.org/entity/Q209896  honorary degree      2   \n",
       "11  http://www.wikidata.org/entity/Q209896  honorary degree      2   \n",
       "12  http://www.wikidata.org/entity/Q209896  honorary degree      2   \n",
       "\n",
       "   organisations                           domains countries pseudoClasses  \n",
       "10                title of honor | academic degree                          \n",
       "11                title of honor | academic degree                          \n",
       "12                title of honor | academic degree                          "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_p.columns = ['uriPer', 'labelPer', 'birthYear', 'uriAw', 'labelAw',\n",
    "                'number', \n",
    "                'organisations', 'domains', 'countries', 'pseudoClasses']\n",
    "print('Number: ',len(df_p))\n",
    "df_p.iloc[10:13,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of awards in relation to 'generations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We adapt the periods manually\n",
    "lc = [1751, 1801, 1851, 1901, 1921, 1941, 1961, 1981, 2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert birthYear to integer\n",
    "df_p.birthYear = df_p.birthYear.apply(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fonction pd.cut : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html\n",
    "# On ajoute une nouvelle colonne qui contient la période sur la base de la liste précédente\n",
    "# et de la valeur de l'année\n",
    "df_p['periods'] = pd.cut(df_p['birthYear'], lc, right=False)\n",
    "\n",
    "### Transformer le code ajouté pour qu'il soit plus lisible\n",
    "# noter qu'on a arrondi les valeurs\n",
    "df_p['periods'] = df_p['periods'].apply(lambda x : str(int(x.left))+'-'+ str(int(x.right)-1))\n",
    "\n",
    "# Inspection\n",
    "df_p.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Group by periods\n",
    "df_period = df_p.groupby(by='periods', observed=True).size()\n",
    "print(df_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_period.plot(kind='bar',rot=50, fontsize=10, figsize=(8,6))\n",
    "ax.bar_label(ax.containers[-1], size=10)\n",
    "plt.ylabel('Number')\n",
    "plt.xlabel('Periods')\n",
    "plt.title('Distribution of awards in relation to generations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_add = 'data/persons_awards.csv'\n",
    "df_p.to_csv(file_add, index=False, sep=',', quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load from CSV\n",
    "\n",
    "file_add = 'data/persons_awards.csv'\n",
    "df_p=pd.read_csv(file_add)\n",
    "print(len(df_p))\n",
    "df_p.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of domains\n",
    "\n",
    "Property **wdt:P279 subclass of**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.sort_values(by='countries', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Award categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['pseudoClasses'] = df_p['pseudoClasses'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35122\n",
      "['academic rank|style|title of authority',\n",
      " 'honorary title|position',\n",
      " 'title of honor']\n"
     ]
    }
   ],
   "source": [
    "### Transform types' strings to alphabetically sorted lists and delete additional white spaces\n",
    "df_p['pseudoClasses'] = df_p['pseudoClasses'].apply(lambda x : '|'.join(sorted([e.strip().lower() for e in x.split('|')])))\n",
    "\n",
    "\n",
    "ll = df_p.pseudoClasses.to_list()\n",
    "print(len(ll))\n",
    "pprint.pprint(ll[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelAw                                                            pseudoClasses                                     \n",
      "Fellow of the American Physical Society                            fellowship award                                      1454\n",
      "Guggenheim Fellowship                                              annual event|scholarship                               833\n",
      "Fellow of the Royal Society                                                                                               778\n",
      "Order of the Red Banner of Labour                                  civil decoration|order|socialist order of merit        575\n",
      "USSR State Prize                                                   official honorary titles of the soviet union|prize     406\n",
      "Order of the Badge of Honour                                       civil decoration|order                                 392\n",
      "Fellow of the American Association for the Advancement of Science  fellowship award                                       376\n",
      "Order of Lenin                                                     order                                                  365\n",
      "Fellow of the American Academy of Arts and Sciences                fellowship award                                       343\n",
      "Knight of the Legion of Honour                                     grade of an order                                      272\n",
      "Foreign Member of the Royal Society                                fellowship award                                       252\n",
      "Lenin Prize                                                                                                               248\n",
      "Stalin Prize                                                                                                              234\n",
      "Gold Medal of the Royal Astronomical Society                       medallion|science award                                225\n",
      "Nobel Prize in Physics                                             physics award|science award                            220\n",
      "Merited Scientist of the Russian Federation                        official honorary title of russia                      214\n",
      "Officer of the Legion of Honour                                    grade of an order                                      194\n",
      "Medal \"For Valiant Labour in the Great Patriotic War 1941–1945\"    medallion                                              175\n",
      "Fellow of the Institute of Physics                                 fellowship award                                       161\n",
      "Knight of the Order of Polonia Restituta                           grade of an order                                      160\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(df_p.groupby(['labelAw','pseudoClasses'])\\\n",
    "              .size().sort_values(ascending=False).iloc[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_addr = 'files/award_pseudoClasses_group.csv'\n",
    "df_p.groupby('pseudoClasses').size().sort_values(ascending=False).to_csv(file_addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Award domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['domains'] = df_p['domains'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform types' strings to alphabetically sorted lists and delete additional white spaces\n",
    "df_p['domains'] = df_p['domains'].apply(lambda x : '|'.join(sorted([e.strip().lower() for e in x.split('|')])))\n",
    "\n",
    "\n",
    "ll = df_p.domains.to_list()\n",
    "print(len(ll))\n",
    "pprint.pprint(ll[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(df_p.groupby(['labelAw','domains'])\\\n",
    "              .size().sort_values(ascending=False).iloc[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_addr = 'files/award_domains_group.csv'\n",
    "df_p.groupby('domains').size().sort_values(ascending=False).to_csv(file_addr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain and type grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(df_p.groupby(['labelAw','pseudoClasses', 'domains'])\\\n",
    "              .size().sort_values(ascending=False).iloc[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_addr = 'files/award_domains_types_grouped.csv'\n",
    "df_p.groupby(['labelAw','pseudoClasses', 'domains']).size().sort_values(ascending=False).to_csv(file_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rebuild the sorted original texts\n",
    "llj = [' | '.join(b) for b in ll]\n",
    "print(len(llj))\n",
    "print(llj[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inspect the available composed types\n",
    "ls = pd.Series(llj)\n",
    "ltg = pd.DataFrame(ls.groupby(by=ls).size().sort_values(ascending=False))\n",
    "ltg.reset_index(inplace=True)\n",
    "ltg.columns=['orgTypeGroup', 'effectif']\n",
    "ltg['numberOrg'] = ltg.orgTypeGroup.apply( lambda x: len(x.split('|')))\n",
    "ltg.iloc[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print to CSV in order to inspect the data\n",
    "csv_file='files/network_organisations_types_groups.csv'\n",
    "ltg.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a graph of the organisations' types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltt = [a for b in df_p.listTypesO.to_list() for a in b]\n",
    "print(len(ltt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = pd.Series(ltt)\n",
    "ls_df = pd.DataFrame(ls.groupby(by=ls).size().sort_values(ascending=False))\n",
    "ls_df.reset_index(inplace=True)\n",
    "ls_df.columns=['orgType', 'number']\n",
    "print(ls_df.head()) \n",
    "print(ls_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distribution of number of types per organisation\n",
    "freq_s = pd.Series([len(e) for e in df_p['listTypesO'].to_list()])\n",
    "print(freq_s.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distribution of types (with minimum value)\n",
    "print(ls_df[ls_df.number > 10].number.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file='files/network_organisations_types.csv'\n",
    "ls_df.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = ls_df[ls_df.number > 10].to_dict(orient='records', index=True)\n",
    "print(ld[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [tuple(\n",
    "    (e['orgType'],\n",
    "     {'number':e['number']}\n",
    "     )) \n",
    "     for e in ls_df.to_dict(orient='records')]\n",
    "print(len(l), l[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(l)\n",
    "print(list(G.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare import\n",
    "fl = [e for e in df_p['listTypesO'].to_dict().items()]\n",
    "print(fl[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### List of distinct organisation types with more than 10 representatives\n",
    "so = list(set(ls_df[ls_df.number > 10].orgType.to_list()))\n",
    "print(len(so), so[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_l = []\n",
    "for a in fl:\n",
    "    if len(a[1]) > 1:\n",
    "        for b in a[1]:\n",
    "            if b in so:\n",
    "                table_l.append((a[0], b))\n",
    "print(table_l[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = pd.DataFrame(table_l, columns=['org_id', 'org_type'])\n",
    "print(len(table_df))\n",
    "table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join on common organisation -> produces a lot of rows !\n",
    "merged = pd.merge(table_df, table_df, on=['org_id'])\n",
    "print(len(merged))\n",
    "merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Eliminate double rows :relationship A-B but relationship B-A\n",
    "merged = merged[merged['org_type_x'] < (merged['org_type_y'])]\n",
    "print(len(merged))\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_merged = pd.DataFrame(merged.groupby(by=['org_type_x', 'org_type_y']).size())\n",
    "gb_merged.reset_index(inplace=True)\n",
    "gb_merged.columns=['org_type_x', 'org_type_y', 'number']\n",
    "gb_merged.iloc[100:120, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide the data in the format \n",
    "# required by Networkx\n",
    "\n",
    "l = [tuple(\n",
    "    (e['org_type_x'], e['org_type_y'],\n",
    "     {'number':e['number']}\n",
    "     )) \n",
    "     for e in gb_merged.to_dict(orient='records')]\n",
    "print(len(l), l[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edges_from(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore graph and it's components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naf.basic_graph_properties(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of graphs, one per component\n",
    "S = [G.subgraph(c).copy() for c in nx.connected_components(G)]\n",
    "\n",
    "### i is the component index in the list S of graphs , len(s.nodes) is the nomber of nodes\n",
    "ln = sorted([[i,len(s.nodes)] for i,s in enumerate(S)], key = lambda row: row[1], reverse=True)\n",
    "print(len (ln))\n",
    "print(ln[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(S[1].nodes.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naf.basic_graph_properties(S[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(S[0].nodes.data())[:3])\n",
    "print(list(S[0].edges.data())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the graph\n",
    "\n",
    "g = S[0]\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 20 #*25\n",
    "\n",
    "graph_layout = 'spring_layout'\n",
    "n_k = 2\n",
    "sc = 1\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "node_size = [n[1]['number'] for n in g.nodes.data()]\n",
    "node_labels = dict([tuple(( n[0] , n[0] ))for n in g.nodes.data()])\n",
    "edge_size = [np.log(n[2]['number']) if n[2]['number'] > 300\n",
    "             else 0  for n in g.edges.data()]\n",
    "font_weight= dict([tuple(( n[0] , 'bold' if n[1]['number'] > 100\n",
    "                            else 'normal' ))\n",
    "                    for n in g.nodes.data()])\n",
    "\n",
    "nx.draw_networkx_nodes(g, pos, node_color='#86B2E4' , node_size=node_size, alpha=0.6)\n",
    "nx.draw_networkx_edges(g, pos, width=edge_size, alpha=0.1) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, font_color='#5B3210', font_weight=font_weight, alpha=0.7, font_size=14)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=60)\n",
    "plt.savefig('images/organisations_types_network_big_component.svg')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All the rest of the small separate components\n",
    "li = [e[0] for e in ln[1:]]\n",
    "pG = nx.Graph()\n",
    "for i in li:\n",
    "    ## ajoute au graphe les composantes en utilisant\n",
    "    # l'index ou position dans la liste de graphes 'S'\n",
    "    pG = nx.union(pG, S[i])\n",
    "print(bipartite.is_bipartite(pG))   \n",
    "naf.basic_graph_properties(pG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the graph\n",
    "\n",
    "g = pG\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 20 #*25\n",
    "\n",
    "graph_layout = 'kamada_kawai'\n",
    "n_k = 2\n",
    "sc = 1\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "node_size = [n[1]['number']*50 for n in g.nodes.data()]\n",
    "node_labels = dict([tuple(( n[0] , n[0] ))for n in g.nodes.data()])\n",
    "edge_size = [np.log(n[2]['number']) if n[2]['number'] > 1\n",
    "             else 0  for n in g.edges.data()]\n",
    "font_weight= dict([tuple(( n[0] , 'bold' if n[1]['number'] > 10\n",
    "                            else 'normal' ))\n",
    "                    for n in g.nodes.data()])\n",
    "\n",
    "nx.draw_networkx_nodes(g, pos, node_color='#86B2E4' , node_size=node_size, alpha=0.6)\n",
    "nx.draw_networkx_edges(g, pos, width=edge_size, alpha=0.1) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, font_color='#5B3210', font_weight=font_weight, alpha=0.7, font_size=14)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=60)\n",
    "plt.savefig('images/organisations_types_network_small_components.svg')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add organisation main type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_organisation_main_type(x):\n",
    "    val = ''\n",
    "    if 'public university' in x:\n",
    "        val = 'public university'\n",
    "    elif 'private university' in x:\n",
    "        val = 'private university'\n",
    "    elif 'institute of technology' in x:\n",
    "        va = 'institute of technology'\n",
    "    elif 'university' in x:\n",
    "        val = 'university'     \n",
    "    elif 'learned society' in x:\n",
    "        val = 'learned society'     \n",
    "    elif 'academy of sciences' in x:\n",
    "        val = 'academy of sciences'\n",
    "    elif 'research institute' in x:\n",
    "        val = 'research institute'\n",
    "    elif 'astronomical observatory' in x:\n",
    "        val = 'astronomical observatory'  \n",
    "    elif 'school' in x:\n",
    "        val = 'high school or similar'         \n",
    "    else:\n",
    "        val = ''\n",
    "\n",
    "    return val        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['orgMainType'] = df_p['typesO'].apply(lambda x : code_organisation_main_type(x))\n",
    "df_p.iloc[7:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_p.groupby(by='orgMainType').size().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikidata 'instance of'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = df_p.listTypesO.to_list()\n",
    "print(len(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltt = [a for b in df_p.listTokensTypesO.to_list() for a in b]\n",
    "print(len(ltt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = pd.Series(ltt)\n",
    "ltg = pd.DataFrame(ls.groupby(by=ls).size().sort_values(ascending=False))\n",
    "ltg.reset_index(inplace=True)\n",
    "ltg.columns=['token', 'effectif']\n",
    "ltg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file='files/network_organisations_types_tokens.csv'\n",
    "ltg.to_csv(csv_file)\n",
    "print(ltg.iloc[30:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph for a given period\n",
    "\n",
    "\n",
    "This is a graph of type 'bipartite', cf. :\n",
    "\n",
    "https://networkx.org/documentation/stable/reference/algorithms/bipartite.html\n",
    "\n",
    "\n",
    "We do not use here the functions related to this kind of graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_1901 = df_p[df_p.periods=='1901-1920'].copy(deep=True)\n",
    "#pprint.pprint(df_p_1901.head(2).to_dict(orient='records'))\n",
    "\n",
    "df_p_1961 = df_p[df_p.periods=='1961-1980'].copy(deep=True)\n",
    "#pprint.pprint(df_p_1961.head(2).to_dict(orient='records'))\n",
    "\n",
    "df_in_use = df_p_1901\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide the data in the format \n",
    "# required by Networkx\n",
    "\n",
    "l = [tuple(\n",
    "    (e['uriPer'], e['uriOrg'],\n",
    "     {'relaType':e['relaType']}\n",
    "     )) \n",
    "     for e in df_in_use.to_dict(orient='records')]\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bip_g = nx.Graph()\n",
    "\n",
    "bip_g.add_edges_from(l)\n",
    "naf.basic_graph_properties(bip_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of types of relationships\n",
    "le = list(bip_g.edges.data())\n",
    "# print([e[2]['relaType'] for e in le][:3]) \n",
    "srt = pd.Series([e[2]['relaType'] for e in le])\n",
    "print(srt.groupby(by=srt).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add metadata to nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p1 = df_in_use[['uriPer','labelPer','birthYear']]\n",
    "df_p1 = df_p1.drop_duplicates()\n",
    "df_p1.columns=['uri', 'label', 'birthYear']\n",
    "df_p1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add data to nodes\n",
    "\n",
    "## Prepare data to import\n",
    "l = dict([(e['uri'],\n",
    "     {'label':e['label'], 'birthYear':e['birthYear'],\n",
    "      'bipartite':0}\n",
    "     ) for e in df_p1.to_dict(orient='records')])\n",
    "# print(str(l)[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Add attributes\n",
    "nx.set_node_attributes(bip_g, l)\n",
    "pprint.pprint(list(bip_g.nodes.data())[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p2 = df_in_use[['uriOrg','labelOrg']]\n",
    "df_p2 = df_p2.drop_duplicates()\n",
    "df_p2.columns=['uri', 'label']\n",
    "df_p2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add data to nodes\n",
    "\n",
    "## Prepare data to import\n",
    "l = dict([(e['uri'],\n",
    "     {'label':e['label'],\n",
    "      'bipartite':1}\n",
    "     ) for e in df_p2.to_dict(orient='records')])\n",
    "# print(str(l)[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Add attributes\n",
    "nx.set_node_attributes(bip_g, l)\n",
    "pprint.pprint(list(bip_g.nodes.data())[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition \n",
    "\n",
    "We can observe that there is one big partition, with approximately 5000 nodes, and around 100 small ones, comprizing 6 nodes or less\n",
    "\n",
    "\n",
    "We first explore small partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of graphs, one per component\n",
    "S = [bip_g.subgraph(c).copy() for c in nx.connected_components(bip_g)]\n",
    "\n",
    "### i is the component index in the list S of graphs , len(s.nodes) is the nomber of nodes\n",
    "ln = sorted([[i,len(s.nodes)] for i,s in enumerate(S)], key = lambda row: row[1], reverse=True)\n",
    "print(len (ln))\n",
    "print(ln[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "li = [6, 12, 30]    # [12, 15, 43]\n",
    "ll = [list(S[i[0]].nodes.data()) for i in ln if i[0] in li ]\n",
    "pprint.pprint(ll[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = li\n",
    "pG = nx.Graph()\n",
    "for i in li:\n",
    "    ## ajoute au graphe les composantes en utilisant\n",
    "    # l'index ou position dans la liste de graphes 'S'\n",
    "    pG = nx.union(pG, S[i])\n",
    "print(bipartite.is_bipartite(pG))   \n",
    "naf.basic_graph_properties(pG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the graph\n",
    "\n",
    "g = pG\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 20 #*25\n",
    "\n",
    "graph_layout = 'kamada_kawai'\n",
    "n_k = 0.8\n",
    "sc = 20\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "node_size = [d[1]*100 for d in nx.degree(g)]\n",
    "node_labels = dict([tuple(( n[0] , n[1]['label'] ))for n in g.nodes.data()])\n",
    "node_colors = ['red' if n[1]['bipartite'] == 0 else 'blue' for n in g.nodes.data()]\n",
    "edge_colors = ['blue' if n[2]['relaType'] == 'employment' \n",
    "               else 'red' if n[2]['relaType'] == 'membership' \n",
    "               else 'green' for n in g.edges.data()]\n",
    "\n",
    "\n",
    "nx.draw_networkx_nodes(g, pos,  node_color=node_colors, node_size=node_size, alpha=0.6)\n",
    "nx.draw_networkx_edges(g, pos, edge_color=edge_colors, width=2, alpha=0.6) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, alpha=0.7, font_size=10)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=60)\n",
    "#plt.savefig('images/small_bipartite_component.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biggest component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [0]\n",
    "big_u = nx.Graph()\n",
    "for i in li:\n",
    "    ## ajoute au graphe les composantes en utilisant\n",
    "    # l'index ou position dans la liste de graphes 'S'\n",
    "    big_u = nx.union(big_u, S[i])\n",
    "print(bipartite.is_bipartite(big_u))   \n",
    "naf.basic_graph_properties(big_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add degree centrality to nodes\n",
    "degree = dict([(d[0], {'degree': d[1]}) for d in nx.degree(big_u)])\n",
    "nx.set_node_attributes(big_u, degree)\n",
    "pprint.pprint(list(big_u.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add eivenvalue to nodes\n",
    "eigenvector = nx.eigenvector_centrality(big_u, max_iter=300)\n",
    "nx.set_node_attributes(big_u, eigenvector, 'eigenvector')\n",
    "pprint.pprint(list(big_u.nodes.data())[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A k-core is a maximal subgraph that contains nodes of degree k or more.\n",
    "# https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.core.core_number.html#networkx.algorithms.core.core_number\n",
    "\n",
    "core_numbers = nx.core_number(big_u)\n",
    "print(str(core_numbers)[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distribution of nodes per core layer\n",
    "l = [v for k,v in core_numbers.items()]\n",
    "ls = pd.Series(l)\n",
    "grouped = ls.groupby(ls).size()\n",
    "\n",
    "\n",
    "ax = grouped.plot.bar(stacked=True, rot=70, fontsize=9, figsize=(10,8))\n",
    "plt.title('Distribution of nodes per layers')\n",
    "\n",
    "## https://stackoverflow.com/questions/71320380/add-only-the-total-values-on-top-of-stacked-bars\n",
    "ax.bar_label(ax.containers[-1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify communities based on core numbers\n",
    "communities = {}\n",
    "for node, core_number in core_numbers.items():\n",
    "    if core_number not in communities:\n",
    "        communities[core_number] = [node]\n",
    "    else:\n",
    "        communities[core_number].append(node)\n",
    "\n",
    "# Print the communities\n",
    "cts = []\n",
    "for core_number, community in communities.items():\n",
    "    print(f\"Community {core_number}: {len(community)}, {community[:5]}\")\n",
    "    cts.append([core_number,len(community),community])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts=sorted(cts, key=lambda x: x[0])\n",
    "p=[pprint.pprint([e[0],e[1],e[2][:3] ]) for e in cts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get all nodes with \n",
    "ln = [ k  for k,v in core_numbers.items()  if v >= 6]\n",
    "print(len(ln), ln[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cG = big_u.subgraph(ln)\n",
    "naf.basic_graph_properties(cG)\n",
    "pprint.pprint(list(cG.nodes.data())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Same result by using the k_core function\n",
    "kc_G = nx.k_core(big_u, 6)\n",
    "naf.basic_graph_properties(kc_G)\n",
    "pprint.pprint(list(kc_G.nodes.data())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot degree distribution\n",
    "d = [d[1] for d in nx.degree(kc_G)]\n",
    "naf.describe_plot_integers_distribution(d, 12,6,'Degree distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "g = kc_G\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 50 #*25\n",
    "\n",
    "graph_layout = 'spring_layout'\n",
    "n_k = 0.5\n",
    "sc = 0.02\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "\n",
    "\n",
    "## on définit ici l'algorythme avec lequel le traphe sera représenté\n",
    "\n",
    "# node_size = [d[1]*100 for d in nx.degree(g)]\n",
    "node_size = [d[1]*10000 for d in nx.eigenvector_centrality(g).items()]\n",
    "#print(node_size)\n",
    "\n",
    "#dict([tuple(( n[0] , n[1]['label'] ))for n in u.nodes.data()])\n",
    "node_labels =  dict(((u), \n",
    "                    str(d['label']))\n",
    "                    for u, d in g.nodes(data=True))\n",
    "\n",
    "node_colors = ['red' if n[1]['bipartite'] == 0 else 'blue' for n in g.nodes.data()]\n",
    "\n",
    "### On représente successivement les différentes sommets et arêtes,\n",
    "# puis on ajoute les labels\n",
    "nx.draw_networkx_nodes(g, pos,  node_color=node_colors, node_size=node_size, alpha=0.2)\n",
    "nx.draw_networkx_edges(g, pos, alpha=0.1) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, alpha=0.8, font_size=20)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=50)\n",
    "plt.savefig('images/biggest_bipartite_component_test.svg')\n",
    "plt.close()\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the degree centrality and eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = pd.DataFrame(kc_G.nodes.data(), columns = ['id', 'attributes'])\n",
    "attributes = pd.json_normalize(export.attributes)\n",
    "\n",
    "export = export.join(pd.json_normalize(export.attributes)).set_index('id')\n",
    "export.drop(columns=['attributes'], inplace=True)\n",
    "round(attributes, 3)\n",
    "export.head(2)\n",
    "#pprint.pprint(list(nd[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Most frequent persons/organisations by degree or eigenvector (replace in the sort clause !)\n",
    "## The degree is definitely higher for universities, but the eigenvector can also be high for persons\n",
    "# and this insofar as they studied in high-degree institutions\n",
    "export.sort_values(by='eigenvector', ascending=False)[['label', 'bipartite', 'degree', 'eigenvector']].iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n",
    "# Different colors per class : https://vitalflux.com/python-scatter-plot-different-classes/\n",
    "# Legend : https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html\n",
    "# Labels : https://stackoverflow.com/questions/14432557/matplotlib-scatter-plot-with-different-text-at-each-data-point\n",
    "\n",
    "\n",
    "### Please note the filter !\n",
    "#  \n",
    "## Values 0 : persons, 1 : organisations  / change rows iloc filter if needed ! \n",
    "exp = export[export.bipartite==0].sort_values(by='eigenvector', ascending=False).iloc[:30]\n",
    "\n",
    "### Adapt image size and police\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "## Please consider:\n",
    "## https://how2matplotlib.com/matplotlib-scatter-label.html\n",
    "\n",
    "plt.scatter(exp['degree'][(exp.bipartite == 0)], \n",
    "            exp['eigenvector'][(exp.bipartite == 0)],\n",
    "           marker='o',\n",
    "           color='Coral',\n",
    "           label='pers'\n",
    "           )\n",
    "plt.scatter(exp['degree'][(exp.bipartite == 1)], #  | (exp.Parti == 'MED')],\n",
    "            exp['eigenvector'][(exp.bipartite == 1)], #  | (exp.Parti == 'MED')],\n",
    "           marker='D',\n",
    "           color='DarkCyan',\n",
    "           label='org')\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('eigenvector')\n",
    "\n",
    "for i,row in list(exp[['label', 'degree','eigenvector']].iterrows()):\n",
    "    plt.annotate(row['label'],(row['degree'], row['eigenvector']))\n",
    "plt.legend(title='Node type')\n",
    "#plt.savefig('plots/sieges_eigenvector_20210526.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n",
    "# Different colors per class : https://vitalflux.com/python-scatter-plot-different-classes/\n",
    "# Legend : https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html\n",
    "# Labels : https://stackoverflow.com/questions/14432557/matplotlib-scatter-plot-with-different-text-at-each-data-point\n",
    "\n",
    "\n",
    "### Please note the filter !\n",
    "#  \n",
    "## Values 0 : persons, 1 : organisations  / change rows iloc filter if needed ! \n",
    "exp = export[export.bipartite==1].sort_values(by='eigenvector', ascending=False).iloc[:30]\n",
    "\n",
    "### Adapt image size and police\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "## Please consider:\n",
    "## https://how2matplotlib.com/matplotlib-scatter-label.html\n",
    "\n",
    "plt.scatter(exp['degree'][(exp.bipartite == 0)], \n",
    "            exp['eigenvector'][(exp.bipartite == 0)],\n",
    "           marker='o',\n",
    "           color='Coral',\n",
    "           label='pers'\n",
    "           )\n",
    "plt.scatter(exp['degree'][(exp.bipartite == 1)], #  | (exp.Parti == 'MED')],\n",
    "            exp['eigenvector'][(exp.bipartite == 1)], #  | (exp.Parti == 'MED')],\n",
    "           marker='D',\n",
    "           color='DarkCyan',\n",
    "           label='org')\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('eigenvector')\n",
    "\n",
    "for i,row in list(exp[['label', 'degree','eigenvector']].iterrows()):\n",
    "    plt.annotate(row['label'],(row['degree'], row['eigenvector']))\n",
    "plt.legend(title='Node type')\n",
    "#plt.savefig('plots/sieges_eigenvector_20210526.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph of persons relationships during studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_p.columns))\n",
    "df_p.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select the columns that will be used\n",
    "df_sel = df_p[df_p.relaType=='education'][['uriPer','uriOrg', 'labelOrg', 'BeginY','EndY', 'periods']].copy(deep=True)\n",
    "print(len(df_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join on common organisation -> produces a lot of rows !\n",
    "merged = pd.merge(df_sel, df_sel, on=['uriOrg', 'labelOrg'])\n",
    "print(len(merged))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Eliminate double rows :relationship A-B but relationship B-A\n",
    "merged = merged[merged['uriPer_x'] < (merged['uriPer_y'])]\n",
    "print(len(merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Restrict time overlap (allow only 8 years overlap) — could be extended to have a larger result\n",
    "merged = merged[(merged['BeginY_y']+2 < merged['EndY_x']-2) & (merged['BeginY_x']+2 < merged['EndY_y']-2)]\n",
    "print(len(merged))\n",
    "merged = merged[['uriPer_x', 'uriPer_y', 'uriOrg', 'labelOrg', 'periods_x', 'BeginY_x', 'EndY_x',  'BeginY_y', 'EndY_y', 'periods_y']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged))\n",
    "print(list(merged.columns))\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Group by persons' pairs and count/aggregate organisations\n",
    "\n",
    "## This is needed because the nx.add_edges_from() function applies\n",
    "# a DISTINCT approach and information will be lost if two persons\n",
    "# are related by more than one organisation \n",
    "\n",
    "gr_mer = merged.groupby(['uriPer_x', 'uriPer_y', 'periods_x', 'BeginY_x', 'EndY_x', 'BeginY_y', 'EndY_y', 'periods_y'], as_index = False)\\\n",
    "    .agg({'labelOrg': '|'.join, 'uriOrg': '|'.join})\n",
    "gr_mer['number'] = gr_mer.labelOrg.apply(lambda x : len(x.split('|')))\n",
    "print(len(gr_mer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change columns names\n",
    "gr_mer.columns= ['uriPer_x', 'uriPer_y', 'periods_x', 'BeginY_x', 'EndY_x', 'BeginY_y', 'EndY_y', 'periods_y', 'orgs', 'uriOrgs', 'numberOrgs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change columns positions\n",
    "gr_mer = gr_mer[['uriPer_x', 'uriPer_y', 'orgs', 'numberOrgs', 'uriOrgs', 'periods_x', 'BeginY_x', 'EndY_x', 'BeginY_y', 'EndY_y', 'periods_y']]\n",
    "gr_mer.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store the information from the SPARQL query in a CSV file\n",
    "# in order to be able to upload it witout executing the query again\n",
    "file_add = 'data/persons_common_education.csv'\n",
    "try:\n",
    "    gr_mer.to_csv(file_add)\n",
    "    print('Written!')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort by multiple relationships\n",
    "gr_mer[['uriPer_x','uriPer_y','orgs','numberOrgs']].sort_values(by='numberOrgs', ascending=False).iloc[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### store multiple relationships in order to explore them in the CSV\n",
    "file_add = 'data/persons_education_rel_multiple.csv'\n",
    "gr_mer[gr_mer.numberOrgs > 1].sort_values(by='numberOrgs', ascending=False).to_csv(file_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of connected persons\n",
    "\n",
    "Displayed with **Allegrograph Gruff**\n",
    "\n",
    "<img src=\"images/alg_gruff_example_chinese_connected_education.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find persons in different periods\n",
    "\n",
    "## We observe that there is significant overlap: more than 30000\n",
    "# Periods are as a matter of fact an artificial construct !\n",
    "\n",
    "print(len(gr_mer[gr_mer.periods_x != gr_mer.periods_y]))\n",
    "gr_mer[gr_mer.periods_x != gr_mer.periods_y].sort_values(by='numberOrgs', ascending=False).iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide the data in the format \n",
    "# required by Networkx\n",
    "\n",
    "l = [tuple(\n",
    "    (e['uriPer_x'], e['uriPer_y'],\n",
    "     {'orgsUris':e['uriOrgs'], 'orgsLabels':e['orgs'], 'orgsNumber':e['numberOrgs'],   \n",
    "      'periods_x':e['periods_x'], 'periods_y':e['periods_y']}\n",
    "     )) \n",
    "     for e in gr_mer.to_dict(orient='records')]\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gr_mer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Créate the empty graph\n",
    "ppG=nx.Graph()\n",
    "\n",
    "## Add relationships to graph\n",
    "# Multiple rows between two edges are taken only once\n",
    "ppG.add_edges_from(l)\n",
    "\n",
    "naf.basic_graph_properties(ppG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add metadata to nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm = df_p[['uriPer','labelPer','birthYear']]\n",
    "df_pm = df_pm.drop_duplicates()\n",
    "df_pm.columns=['uri', 'label', 'birthYear']\n",
    "df_pm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare data to add to nodes\n",
    "ln = dict([(e['uri'],\n",
    "     {'label':e['label'], 'birthYear':e['birthYear']}\n",
    "     ) for e in df_pm.to_dict(orient='records')])\n",
    "# print(str(l)[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Add attributes\n",
    "nx.set_node_attributes(ppG, ln)\n",
    "pprint.pprint(list(ppG.nodes.data())[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the education relationships graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naf.basic_graph_properties(ppG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of graphs, one per component\n",
    "perS = [ppG.subgraph(c).copy() for c in nx.connected_components(ppG)]\n",
    "\n",
    "### i is the component index in the list S of graphs , len(s.nodes) is the nomber of nodes\n",
    "ln = sorted([[i,len(s.nodes)] for i,s in enumerate(perS)], key = lambda row: row[1], reverse=True)\n",
    "print(ln[:5])\n",
    "\n",
    "### Again we observe that there is a big connected graphe \n",
    "# and a multitude of small graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore small graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "li = [117]    # [12, 15, 43]\n",
    "ll = [list(perS[i[0]].nodes.data()) for i in ln if i[0] in li ]\n",
    "#pprint.pprint(str(ll)[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display variable\n",
    "\n",
    "u_117 = nx.Graph()\n",
    "\n",
    "for i in li:\n",
    "    ## ajoute au graphe les composantes en utilisant\n",
    "    # l'index ou position dans la liste de graphes 'S'\n",
    "    u_117 = nx.union(u_117, perS[i])\n",
    "naf.basic_graph_properties(u_117)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "g = u_117\n",
    "\n",
    "# print(list(g.nodes.data())[:3])\n",
    "# print(list(g.edges.data())[:3])\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 30 #*25\n",
    "\n",
    "graph_layout = 'kamada_kawai'\n",
    "n_k = 0.4\n",
    "sc = 0.02\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "node_size = [d[1]*100 for d in nx.degree(g)]\n",
    "node_labels = dict([tuple(( n[0] , n[1]['label'] ))for n in g.nodes.data()])\n",
    "print(node_labels)\n",
    "edge_labels = {e: g.get_edge_data(e[0], e[1])[\"orgsLabels\"] for e in g.edges()}\n",
    "print(edge_labels)\n",
    "\n",
    "\n",
    "### On représente successivement les différentes sommets et arêtes,\n",
    "# puis on ajoute les labels\n",
    "nx.draw_networkx_nodes(g, pos,  node_size=node_size, alpha=0.4)\n",
    "nx.draw_networkx_edges(g, pos, label=edge_labels, width=4, alpha=0.2) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, alpha=0.7, font_size=20)\n",
    "nx.draw_networkx_edge_labels(g, pos=pos, edge_labels=edge_labels, alpha=0.6)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=50)\n",
    "#plt.savefig('images/small_bipartite_component.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p[(df_p.labelOrg.str.contains('Kyiv Poly'))& df_p.relaType.str.contains('educa')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composante principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [0]\n",
    "big_ppG = nx.Graph()\n",
    "for i in li:\n",
    "    ## ajoute au graphe les composantes en utilisant\n",
    "    # l'index ou position dans la liste de graphes 'S'\n",
    "    big_ppG = nx.union(big_ppG, perS[i])\n",
    "\n",
    "naf.basic_graph_properties(big_ppG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(list(big_ppG.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add degree centrality to nodes\n",
    "degree = dict([(d[0], {'degree': d[1]}) for d in nx.degree(big_ppG)])\n",
    "nx.set_node_attributes(big_ppG, degree)\n",
    "pprint.pprint(list(big_ppG.nodes.data())[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree distribution and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot degree distribution\n",
    "d = [d[1] for d in nx.degree(big_ppG)]\n",
    "naf.describe_plot_integers_distribution(d, 50,6,'Degree distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add eigenvector to nodes\n",
    "\n",
    "## If error: PowerIterationFailedConvergence: (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')\n",
    "# increase number of max iterations\n",
    "eigenvector = nx.eigenvector_centrality(big_ppG, max_iter=200)\n",
    "nx.set_node_attributes(big_ppG, eigenvector, 'eigenvector')\n",
    "pprint.pprint(list(big_ppG.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot eigenvector density distribution \n",
    "eigenvector_s = pd.Series(list(eigenvector.values()))\n",
    "stats = eigenvector_s.describe()\n",
    "\n",
    "# Format decimal values\n",
    "stats = stats.apply(lambda x: format(x, '.20f'))\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of eigenvector density\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "p = sns.violinplot(data=eigenvector_s[eigenvector_s> 0.00013610493515402787], orient='h')\n",
    "plt.title('Eigenvector Distribution Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(eigenvector_s[eigenvector_s> 0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export node attributes to dataframe\n",
    "nodes_data ={node: big_ppG.nodes[node] for node in big_ppG.nodes}\n",
    "nodes_df = pd.DataFrame(nodes_data).T\n",
    "nodes_df.reset_index(inplace=True)\n",
    "nodes_df.columns = ['personUri', 'label', 'birthYear','degree','eigenvector']\n",
    "nodes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "exp = nodes_df.sort_values(by='eigenvector', ascending=False).iloc[:300]\n",
    "\n",
    "### Adapt image size and police\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "plt.scatter(exp['degree'],\n",
    "            exp['eigenvector'],\n",
    "           marker='o',\n",
    "           color='DarkCyan'\n",
    "           )\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('eigenvector')\n",
    "\n",
    "for i,row in list(exp[['label', 'degree','eigenvector']].iterrows()):\n",
    "    plt.annotate(row['label'],(row['degree'], row['eigenvector']),\n",
    "                 fontsize=7)\n",
    "#plt.legend(title='Node type')\n",
    "#plt.savefig('plots/sieges_eigenvector_20210526.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_high_egv = nodes_df['personUri'][nodes_df.eigenvector> 0.01].to_list()\n",
    "print(len(persons_high_egv), persons_high_egv[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_mer.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecting_orgs = gr_mer[(gr_mer.uriPer_x.isin(persons_high_egv))|(gr_mer.uriPer_y.isin(persons_high_egv))].groupby(by='orgs').size()\n",
    "file_add='data/connecting_orgs.csv'\n",
    "connecting_orgs.sort_values(ascending=False).to_csv(file_add)\n",
    "print(connecting_orgs.sort_values(ascending=False).iloc[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing with cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A k-core is a maximal subgraph that contains nodes of degree k or more.\n",
    "# https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.core.core_number.html#networkx.algorithms.core.core_number\n",
    "core_numbers = nx.core_number(big_ppG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distribution of nodes per core layer\n",
    "l = [v for k,v in core_numbers.items()]\n",
    "ls = pd.Series(l)\n",
    "grouped = ls.groupby(ls).size()\n",
    "\n",
    "\n",
    "ax = grouped.plot.bar(stacked=True, rot=70, fontsize=9, figsize=(20,8))\n",
    "plt.title('Distribution of nodes per core layers')\n",
    "\n",
    "## https://stackoverflow.com/questions/71320380/add-only-the-total-values-on-top-of-stacked-bars\n",
    "ax.bar_label(ax.containers[-1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify communities based on core numbers\n",
    "communities = {}\n",
    "for node, core_number in core_numbers.items():\n",
    "    if core_number not in communities:\n",
    "        communities[core_number] = [node]\n",
    "    else:\n",
    "        communities[core_number].append(node)\n",
    "\n",
    "# Print the communities\n",
    "cts = []\n",
    "for core_number, community in communities.items():\n",
    "    # print(f\"Community {core_number}: {len(community)}, {community[:5]}\")\n",
    "    cts.append([core_number,len(community),community])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts=sorted(cts, key=lambda x: x[0])\n",
    "pprint.pprint([[e[0], e[1] ] for e in cts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "ln = [ k  for k,v in core_numbers.items()  if v >= 65]\n",
    "print(len(ln), ln[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG = big_ppG.subgraph(ln)\n",
    "naf.basic_graph_properties(SG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add betweenness to nodes\n",
    "\n",
    "# !!! trop long sur tout le graphe SI le graph est grand !!!\n",
    "\n",
    "betweenness = nx.betweenness_centrality(SG)\n",
    "nx.set_node_attributes(SG, betweenness, 'betweenness')\n",
    "pprint.pprint(list(SG.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "g = SG\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 20 #*25\n",
    "\n",
    "graph_layout = 'spring_layout'\n",
    "n_k = 0.4\n",
    "sc = 0.05\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "\n",
    "\n",
    "## on définit ici l'algorythme avec lequel le traphe sera représenté\n",
    "\n",
    "# node_size = [d[1]*100 for d in nx.degree(g)]\n",
    "#node_size = [d[1]*10000 for d in nx.eigenvector_centrality(g).items()]\n",
    "node_size = [n[1]['betweenness']*1000000+10 for n in g.nodes.data()]\n",
    "#print(node_size)\n",
    "\n",
    "#dict([tuple(( n[0] , n[1]['label'] ))for n in u.nodes.data()])\n",
    "node_labels =  dict(((u), \n",
    "                    str(d['label']))\n",
    "                    for u, d in g.nodes(data=True))\n",
    "\n",
    "node_colors = 'blue'\n",
    "\n",
    "### On représente successivement les différentes sommets et arêtes,\n",
    "# puis on ajoute les labels\n",
    "nx.draw_networkx_nodes(g, pos,  node_color=node_colors, node_size=node_size, alpha=0.2)\n",
    "nx.draw_networkx_edges(g, pos, alpha=0.1) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, alpha=0.8, font_size=20)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=50)\n",
    "plt.savefig('images/biggest_education_relationships_component_test.svg')\n",
    "plt.close()\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New graphs by period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_mer.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 1851-1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_mer_1851_1900 = gr_mer[(gr_mer.periods_x=='1851-1900')|(gr_mer.periods_y=='1851-1900')].copy(deep=True)\n",
    "len(gr_mer_1851_1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distribution of relationships number\n",
    "print(gr_mer_1851_1900.groupby(by='numberOrgs').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide the data in the format \n",
    "# required by Networkx\n",
    "\n",
    "l = [tuple(\n",
    "    (e['uriPer_x'], e['uriPer_y'],\n",
    "     {'orgsUris':e['uriOrgs'], 'orgsLabels':e['orgs'], 'orgsNumber':e['numberOrgs'],   \n",
    "      'periods_x':e['periods_x'], 'periods_y':e['periods_y']}\n",
    "     )) \n",
    "     for e in gr_mer_1851_1900.to_dict(orient='records')]\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Créate the empty graph\n",
    "ppG=nx.Graph()\n",
    "\n",
    "## Add relationships to graph\n",
    "# Multiple rows between two edges are taken only once\n",
    "ppG.add_edges_from(l)\n",
    "\n",
    "naf.basic_graph_properties(ppG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare data to add to nodes\n",
    "ln = dict([(e['uri'],\n",
    "     {'label':e['label'], 'birthYear':e['birthYear']}\n",
    "     ) for e in df_pm.to_dict(orient='records')])\n",
    "# print(str(l)[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Add attributes\n",
    "nx.set_node_attributes(ppG, ln)\n",
    "pprint.pprint(list(ppG.nodes.data())[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of graphs, one per component\n",
    "perS = [ppG.subgraph(c).copy() for c in nx.connected_components(ppG)]\n",
    "\n",
    "### i is the component index in the list S of graphs , len(s.nodes) is the nomber of nodes\n",
    "ln = sorted([[i,len(s.nodes)] for i,s in enumerate(perS)], key = lambda row: row[1], reverse=True)\n",
    "print(ln[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [0]\n",
    "big_ppG = nx.Graph()\n",
    "for i in li:\n",
    "    ## ajoute au graphe les composantes en utilisant\n",
    "    # l'index ou position dans la liste de graphes 'S'\n",
    "    big_ppG = nx.union(big_ppG, perS[i])\n",
    "\n",
    "naf.basic_graph_properties(big_ppG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add degree centrality to nodes\n",
    "degree = dict([(d[0], {'degree': d[1]}) for d in nx.degree(big_ppG)])\n",
    "nx.set_node_attributes(big_ppG, degree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot degree distribution\n",
    "d = [d[1] for d in nx.degree(big_ppG)]\n",
    "naf.describe_plot_integers_distribution(d, 50,6,'Degree distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add eigenvector to nodes\n",
    "\n",
    "## If error: PowerIterationFailedConvergence: (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')\n",
    "# increase number of max iterations\n",
    "eigenvector = nx.eigenvector_centrality(big_ppG, max_iter=200)\n",
    "nx.set_node_attributes(big_ppG, eigenvector, 'eigenvector')\n",
    "pprint.pprint(list(big_ppG.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot eigenvector density distribution \n",
    "eigenvector_s = pd.Series(list(eigenvector.values()))\n",
    "stats = eigenvector_s.describe()\n",
    "\n",
    "# Format decimal values\n",
    "stats = stats.apply(lambda x: format(x, '.20f'))\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export node attributes to dataframe\n",
    "nodes_data ={node: big_ppG.nodes[node] for node in big_ppG.nodes}\n",
    "nodes_df = pd.DataFrame(nodes_data).T\n",
    "nodes_df.reset_index(inplace=True)\n",
    "nodes_df.columns = ['personUri', 'label', 'birthYear','degree','eigenvector']\n",
    "nodes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "exp = nodes_df.sort_values(by='eigenvector', ascending=False).iloc[:30]\n",
    "\n",
    "### Adapt image size and police\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "plt.scatter(exp['degree'],\n",
    "            exp['eigenvector'],\n",
    "           marker='o',\n",
    "           color='DarkCyan'\n",
    "           )\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('eigenvector')\n",
    "\n",
    "for i,row in list(exp[['label', 'degree','eigenvector']].iterrows()):\n",
    "    plt.annotate(row['label'],(row['degree'], row['eigenvector']),\n",
    "                 fontsize=7)\n",
    "#plt.legend(title='Node type')\n",
    "#plt.savefig('plots/sieges_eigenvector_20210526.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_high_egv = nodes_df['personUri'][nodes_df.eigenvector> 0.01].to_list()\n",
    "print(len(persons_high_egv), persons_high_egv[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecting_orgs = gr_mer[(gr_mer.uriPer_x.isin(persons_high_egv))|(gr_mer.uriPer_y.isin(persons_high_egv))].groupby(by='orgs').size()\n",
    "# file_add='data/connecting_orgs.csv'\n",
    "# connecting_orgs.sort_values(ascending=False).to_csv(file_add)\n",
    "print(connecting_orgs.sort_values(ascending=False).iloc[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add betweenness to nodes\n",
    "\n",
    "# !!! trop long sur tout le graphe SI le graph est grand !!!\n",
    "\n",
    "betweenness = nx.betweenness_centrality(big_ppG)\n",
    "nx.set_node_attributes(big_ppG, betweenness, 'betweenness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(list(big_ppG.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export node attributes to dataframe\n",
    "nodes_data ={node: big_ppG.nodes[node] for node in big_ppG.nodes}\n",
    "nodes_df = pd.DataFrame(nodes_data).T\n",
    "nodes_df.reset_index(inplace=True)\n",
    "nodes_df.columns = ['personUri', 'label', 'birthYear','degree','eigenvector', 'betweenness']\n",
    "nodes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df.sort_values(by=['eigenvector', 'betweenness'], ascending=False).iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "\n",
    "\n",
    "exp_eig = nodes_df.sort_values(by=['eigenvector', 'betweenness'], ascending=False).iloc[:30]\n",
    "exp_betw = nodes_df.sort_values(by=['betweenness', 'eigenvector'], ascending=False).iloc[:30]\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,20) ) #  sharey=True, \n",
    "\n",
    "ax[0].scatter(exp_eig['eigenvector'],\n",
    "            exp_eig['betweenness'],\n",
    "           marker='o',\n",
    "           color='DarkCyan'\n",
    "           )\n",
    "ax[0].set_xlabel('eigenvector')\n",
    "ax[0].set_ylabel('betweenness')\n",
    "\n",
    "for i,row in list(exp_eig[['label', 'eigenvector','betweenness']].iterrows()):\n",
    "    ax[0].annotate(row['label'],(row['eigenvector'], row['betweenness']),\n",
    "                 fontsize=10)\n",
    "    \n",
    "\n",
    "ax[1].scatter(exp_betw['betweenness'],\n",
    "            exp_betw['eigenvector'],\n",
    "           marker='o',\n",
    "           color='DarkCyan'\n",
    "           )\n",
    "ax[1].set_xlabel('betweenness')\n",
    "ax[1].set_ylabel('eigenvector')\n",
    "\n",
    "for i,row in list(exp_betw[['label', 'betweenness','eigenvector']].iterrows()):\n",
    "    ax[1].annotate(row['label'],(row['betweenness'], row['eigenvector']),\n",
    "                 fontsize=10)\n",
    "\n",
    "\n",
    "\n",
    "#plt.legend(title='Node type')\n",
    "#plt.savefig('plots/sieges_eigenvector_20210526.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the graph with eigenvector centrality\n",
    "\n",
    "# Position the nodes\n",
    "pos = nx.spring_layout(big_ppG, k=0.2)\n",
    "\n",
    "#node_size = [e[1]*500+10 for e in le]\n",
    "degrees = [d[1] for d in big_ppG.degree()]\n",
    "max_degree = max(degrees)\n",
    "print(max_degree)\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('Dark2')\n",
    "\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# Draw the nodes and edges\n",
    "#nx.draw_networkx_nodes(big_ppG, pos, ax=ax)\n",
    "nx.draw_networkx_edges(big_ppG, pos, ax=ax)\n",
    "\n",
    "# Create the ellipses\n",
    "for node in big_ppG.nodes():\n",
    "    width = big_ppG.nodes[node]['eigenvector']*0.7\n",
    "    height = big_ppG.nodes[node]['betweenness']*0.7\n",
    "    x, y = pos[node]\n",
    "    degree = big_ppG.degree(node)\n",
    "    color = cmap(degree / max_degree)\n",
    "    ellipse = patches.Ellipse((x, y), width, height, alpha=0.5, facecolor=color)\n",
    "    ax.add_patch(ellipse)\n",
    "nx.draw_networkx_labels(big_ppG, pos) # ,  horizontalalignment='left'\n",
    "# Set the limits and labels\n",
    "#ax.set_xlim(min(pos.values(), key=lambda x: x[0])[0] - 10, max(pos.values(), key=lambda x: x[0])[0] + 10)\n",
    "#ax.set_ylim(min(pos.values(), key=lambda x: x[1])[1] - 10, max(pos.values(), key=lambda x: x[1])[1] + 10)\n",
    "ax.set_title('Ellipse Plot of NetworkX Graph')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### betweenness distribution \n",
    "betweenness_s = pd.Series(list(betweenness.values()))\n",
    "\n",
    "stats = betweenness_s.describe()\n",
    "\n",
    "# Format decimal values\n",
    "stats = stats.apply(lambda x: format(x, '.20f'))\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "g = big_ppG\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 20 #*25\n",
    "\n",
    "graph_layout = 'spring_layout'\n",
    "n_k = 0.4\n",
    "sc = 0.05\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "\n",
    "\n",
    "## on définit ici l'algorythme avec lequel le traphe sera représenté\n",
    "\n",
    "# node_size = [d[1]*100 for d in nx.degree(g)]\n",
    "#node_size = [d[1]*10000 for d in nx.eigenvector_centrality(g).items()]\n",
    "node_size = [n[1]['betweenness']*1000000+10 for n in g.nodes.data()]\n",
    "#print(node_size)\n",
    "\n",
    "#dict([tuple(( n[0] , n[1]['label'] ))for n in u.nodes.data()])\n",
    "node_labels =  dict(((u), \n",
    "                    str(d['label']))\n",
    "                    for u, d in g.nodes(data=True))\n",
    "\n",
    "node_colors = 'blue'\n",
    "\n",
    "### On représente successivement les différentes sommets et arêtes,\n",
    "# puis on ajoute les labels\n",
    "nx.draw_networkx_nodes(g, pos,  node_color=node_colors, node_size=node_size, alpha=0.2)\n",
    "nx.draw_networkx_edges(g, pos, alpha=0.1) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, alpha=0.8, font_size=20)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=50)\n",
    "plt.savefig('images/biggest_education_relationships_component_1851_1900.svg')\n",
    "plt.close()\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A k-core is a maximal subgraph that contains nodes of degree k or more.\n",
    "# https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.core.core_number.html#networkx.algorithms.core.core_number\n",
    "core_numbers = nx.core_number(big_ppG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distribution of nodes per core layer\n",
    "l = [v for k,v in core_numbers.items()]\n",
    "ls = pd.Series(l)\n",
    "grouped = ls.groupby(ls).size()\n",
    "\n",
    "\n",
    "ax = grouped.plot.bar(stacked=True, rot=70, fontsize=9, figsize=(20,8))\n",
    "plt.title('Distribution of nodes per core layers')\n",
    "\n",
    "## https://stackoverflow.com/questions/71320380/add-only-the-total-values-on-top-of-stacked-bars\n",
    "ax.bar_label(ax.containers[-1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "ln = [ k  for k,v in core_numbers.items()  if v > 10]\n",
    "print(len(ln), ln[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naf.basic_graph_properties(big_ppG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG = big_ppG.subgraph(ln)\n",
    "naf.basic_graph_properties(SG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = betweenness_s.sort_values(ascending=False).iloc[40]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "g = SG\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 20 #*25\n",
    "\n",
    "graph_layout = 'spring_layout'\n",
    "n_k = 0.7\n",
    "sc = 0.05\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "\n",
    "\n",
    "## on définit ici l'algorythme avec lequel le traphe sera représenté\n",
    "\n",
    "# node_size = [d[1]*100 for d in nx.degree(g)]\n",
    "#node_size = [d[1]*10000 for d in nx.eigenvector_centrality(g).items()]\n",
    "node_size = [n[1]['betweenness']*500000+20 for n in g.nodes.data()]\n",
    "#print(node_size)\n",
    "\n",
    "\n",
    "\n",
    "## label only for the 10 most relevant intermediaries\n",
    "node_labels =  dict(((u), \n",
    "                    str(d['label']))\n",
    "                    if d['betweenness'] > b \n",
    "                    else ((u), \n",
    "                    str(''))\n",
    "                    for u, d in g.nodes(data=True))\n",
    "print(node_labels)\n",
    "\n",
    "node_colors = 'blue'\n",
    "\n",
    "### On représente successivement les différentes sommets et arêtes,\n",
    "# puis on ajoute les labels\n",
    "nx.draw_networkx_nodes(g, pos,  node_color=node_colors, node_size=node_size, alpha=0.2)\n",
    "nx.draw_networkx_edges(g, pos, alpha=0.02) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, alpha=0.8, font_size=20)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=50)\n",
    "plt.savefig('images/biggest_sliced_education_relationships_component_1851_1900.svg')\n",
    "plt.close()\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Egograph based on eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei = sorted([n[1]['eigenvector'] for n in big_ppG.nodes.data()], reverse=True)[10]\n",
    "print(ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = [n[0] for n in big_ppG.nodes.data() if n[1]['eigenvector'] >= ei ]\n",
    "print(len(ln), ln[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_graph = nx.ego_graph(big_ppG, ln[1], radius=2)\n",
    "egn = list(ego_graph.nodes())\n",
    "print(egn[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display variable\n",
    "\n",
    "egos_graph = nx.Graph()\n",
    "\n",
    "l_nodes=[]\n",
    "i = 0\n",
    "while i < len(ln):\n",
    "    ego_graph = nx.ego_graph(big_ppG, ln[1], radius=3)\n",
    "    egn = list(ego_graph.nodes())\n",
    "    l_nodes += egn\n",
    "    i += 1\n",
    "\n",
    "egos_graph = nx.subgraph(big_ppG, l_nodes)\n",
    "\n",
    "naf.basic_graph_properties(egos_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(list(egos_graph.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei2 = sorted([n[1]['eigenvector'] for n in big_ppG.nodes.data()], reverse=True)[50]\n",
    "print(ei2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "g = egos_graph\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 20 #*25\n",
    "\n",
    "graph_layout = 'spring_layout'\n",
    "n_k = 0.7\n",
    "sc = 0.05\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "\n",
    "\n",
    "## on définit ici l'algorythme avec lequel le traphe sera représenté\n",
    "\n",
    "# node_size = [d[1]*100 for d in nx.degree(g)]\n",
    "#node_size = [d[1]*10000 for d in nx.eigenvector_centrality(g).items()]\n",
    "node_size = [n[1]['eigenvector']*50000+20 for n in g.nodes.data()]\n",
    "#print(node_size)\n",
    "\n",
    "\n",
    "\n",
    "## label only for the 10 most relevant intermediaries\n",
    "node_labels =  dict(((u), \n",
    "                    str(d['label']))\n",
    "                    if d['eigenvector'] >= ei2\n",
    "                    else ((u), \n",
    "                    str(''))\n",
    "                    for u, d in g.nodes(data=True))\n",
    "#print(node_labels)\n",
    "\n",
    "node_colors = 'blue'\n",
    "\n",
    "### On représente successivement les différentes sommets et arêtes,\n",
    "# puis on ajoute les labels\n",
    "nx.draw_networkx_nodes(g, pos,  node_color=node_colors, node_size=node_size, alpha=0.2)\n",
    "nx.draw_networkx_edges(g, pos, alpha=0.02) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, alpha=0.8, font_size=20)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=50)\n",
    "plt.savefig('images/biggest_egos_education_relationships_component_1851_1900.svg')\n",
    "plt.close()\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export node attributes to dataframe\n",
    "nodes_data ={node: egos_graph.nodes[node] for node in egos_graph.nodes}\n",
    "nodes_df = pd.DataFrame(nodes_data).T\n",
    "nodes_df.reset_index(inplace=True)\n",
    "nodes_df.columns = ['personUri', 'label', 'birthYear','degree','eigenvector', 'betweenness']\n",
    "nodes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "exp = nodes_df.sort_values(by='betweenness', ascending=False).iloc[:50]\n",
    "\n",
    "### Adapt image size and police\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "plt.scatter(exp['eigenvector'],\n",
    "           exp['betweenness'],\n",
    "            marker='o',\n",
    "           color='DarkCyan'\n",
    "           )\n",
    "plt.xlabel('eigenvector')\n",
    "plt.ylabel('betweenness')\n",
    "\n",
    "for i,row in list(exp[['label','eigenvector', 'betweenness']].iterrows()):\n",
    "    plt.annotate(row['label'],( row['eigenvector'],row['betweenness']),\n",
    "                 fontsize=7)\n",
    "#plt.legend(title='Node type')\n",
    "#plt.savefig('plots/sieges_eigenvector_20210526.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_high_egv = nodes_df['personUri'][nodes_df.eigenvector> ei2].to_list()\n",
    "print(len(persons_high_egv), persons_high_egv[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecting_orgs = gr_mer[(gr_mer.uriPer_x.isin(persons_high_egv))|(gr_mer.uriPer_y.isin(persons_high_egv))].groupby(by='orgs').size()\n",
    "# file_add='data/connecting_orgs.csv'\n",
    "# connecting_orgs.sort_values(ascending=False).to_csv(file_add)\n",
    "print(connecting_orgs.sort_values(ascending=False).iloc[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Reste à faire:\n",
    "\n",
    "* ajouter les poids sur les relations pour calcules les paramètres de centralité\n",
    "* vérifier s'il y a une correlation entre prix obtenus et centralité dans le réseau des études\n",
    "* vérifier s'il y a correlation entre étudier ensemble et publier ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 1901-1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_mer_1901_1920 = gr_mer[(gr_mer.periods_x=='1901-1920')|(gr_mer.periods_y=='1901-1920')].copy(deep=True)\n",
    "print(len(gr_mer_1901_1920))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distribution of relationships number\n",
    "print(gr_mer_1901_1920.groupby(by='numberOrgs').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Provide the data in the format \n",
    "# required by Networkx\n",
    "\n",
    "l = [tuple(\n",
    "    (e['uriPer_x'], e['uriPer_y'],\n",
    "     {'orgsUris':e['uriOrgs'], 'orgsLabels':e['orgs'], 'orgsNumber':e['numberOrgs'],   \n",
    "      'periods_x':e['periods_x'], 'periods_y':e['periods_y']}\n",
    "     )) \n",
    "     for e in gr_mer_1901_1920.to_dict(orient='records')]\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Créate the empty graph\n",
    "ppG=nx.Graph()\n",
    "\n",
    "## Add relationships to graph\n",
    "# Multiple rows between two edges are taken only once\n",
    "ppG.add_edges_from(l)\n",
    "\n",
    "naf.basic_graph_properties(ppG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare data to add to nodes\n",
    "ln = dict([(e['uri'],\n",
    "     {'label':e['label'], 'birthYear':e['birthYear']}\n",
    "     ) for e in df_pm.to_dict(orient='records')])\n",
    "# print(str(l)[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Add attributes\n",
    "nx.set_node_attributes(ppG, ln)\n",
    "pprint.pprint(list(ppG.nodes.data())[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of graphs, one per component\n",
    "perS = [ppG.subgraph(c).copy() for c in nx.connected_components(ppG)]\n",
    "\n",
    "### i is the component index in the list S of graphs , len(s.nodes) is the nomber of nodes\n",
    "ln = sorted([[i,len(s.nodes)] for i,s in enumerate(perS)], key = lambda row: row[1], reverse=True)\n",
    "print(ln[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [0]\n",
    "big_ppG = nx.Graph()\n",
    "for i in li:\n",
    "    ## ajoute au graphe les composantes en utilisant\n",
    "    # l'index ou position dans la liste de graphes 'S'\n",
    "    big_ppG = nx.union(big_ppG, perS[i])\n",
    "\n",
    "naf.basic_graph_properties(big_ppG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add degree centrality to nodes\n",
    "degree = dict([(d[0], {'degree': d[1]}) for d in nx.degree(big_ppG)])\n",
    "nx.set_node_attributes(big_ppG, degree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot degree distribution\n",
    "d = [d[1] for d in nx.degree(big_ppG)]\n",
    "naf.describe_plot_integers_distribution(d, 50,6,'Degree distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add eigenvector to nodes\n",
    "\n",
    "## If error: PowerIterationFailedConvergence: (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')\n",
    "# increase number of max iterations\n",
    "eigenvector = nx.eigenvector_centrality(big_ppG, max_iter=200)\n",
    "nx.set_node_attributes(big_ppG, eigenvector, 'eigenvector')\n",
    "pprint.pprint(list(big_ppG.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot eigenvector density distribution \n",
    "eigenvector_s = pd.Series(list(eigenvector.values()))\n",
    "stats = eigenvector_s.describe()\n",
    "\n",
    "# Format decimal values\n",
    "stats = stats.apply(lambda x: format(x, '.20f'))\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export node attributes to dataframe\n",
    "nodes_data ={node: big_ppG.nodes[node] for node in big_ppG.nodes}\n",
    "nodes_df = pd.DataFrame(nodes_data).T\n",
    "nodes_df.reset_index(inplace=True)\n",
    "nodes_df.columns = ['personUri', 'label', 'birthYear','degree','eigenvector']\n",
    "nodes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "exp = nodes_df.sort_values(by='eigenvector', ascending=False).iloc[:300]\n",
    "\n",
    "### Adapt image size and police\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "plt.scatter(exp['degree'],\n",
    "            exp['eigenvector'],\n",
    "           marker='o',\n",
    "           color='DarkCyan'\n",
    "           )\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('eigenvector')\n",
    "\n",
    "for i,row in list(exp[['label', 'degree','eigenvector']].iterrows()):\n",
    "    plt.annotate(row['label'],(row['degree'], row['eigenvector']),\n",
    "                 fontsize=7)\n",
    "#plt.legend(title='Node type')\n",
    "#plt.savefig('plots/sieges_eigenvector_20210526.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_high_egv = nodes_df['personUri'][nodes_df.eigenvector> 0.01].to_list()\n",
    "print(len(persons_high_egv), persons_high_egv[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecting_orgs = gr_mer[(gr_mer.uriPer_x.isin(persons_high_egv))|(gr_mer.uriPer_y.isin(persons_high_egv))].groupby(by='orgs').size()\n",
    "# file_add='data/connecting_orgs.csv'\n",
    "# connecting_orgs.sort_values(ascending=False).to_csv(file_add)\n",
    "print(connecting_orgs.sort_values(ascending=False).iloc[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add betweenness to nodes\n",
    "\n",
    "# !!! trop long sur tout le graphe SI le graph est grand !!!\n",
    "\n",
    "betweenness = nx.betweenness_centrality(big_ppG)\n",
    "nx.set_node_attributes(big_ppG, betweenness, 'betweenness')\n",
    "pprint.pprint(list(big_ppG.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([e[1] for e in list(betweenness.items())][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### betweenness distribution \n",
    "betweenness_s = pd.Series(list(betweenness.values()))\n",
    "\n",
    "stats = betweenness_s.describe()\n",
    "\n",
    "# Format decimal values\n",
    "stats = stats.apply(lambda x: format(x, '.20f'))\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A k-core is a maximal subgraph that contains nodes of degree k or more.\n",
    "# https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.core.core_number.html#networkx.algorithms.core.core_number\n",
    "core_numbers = nx.core_number(big_ppG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distribution of nodes per core layer\n",
    "l = [v for k,v in core_numbers.items()]\n",
    "ls = pd.Series(l)\n",
    "grouped = ls.groupby(ls).size()\n",
    "\n",
    "\n",
    "ax = grouped.plot.bar(stacked=True, rot=70, fontsize=9, figsize=(20,8))\n",
    "plt.title('Distribution of nodes per core layers')\n",
    "\n",
    "## https://stackoverflow.com/questions/71320380/add-only-the-total-values-on-top-of-stacked-bars\n",
    "ax.bar_label(ax.containers[-1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "ln = [ k  for k,v in core_numbers.items()  if v > 10]\n",
    "print(len(ln), ln[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naf.basic_graph_properties(big_ppG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG = big_ppG.subgraph(ln)\n",
    "naf.basic_graph_properties(SG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = betweenness_s.sort_values(ascending=False).iloc[40]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "g = SG\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 20 #*25\n",
    "\n",
    "graph_layout = 'spring_layout'\n",
    "n_k = 0.7\n",
    "sc = 0.05\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "\n",
    "\n",
    "## on définit ici l'algorythme avec lequel le traphe sera représenté\n",
    "\n",
    "# node_size = [d[1]*100 for d in nx.degree(g)]\n",
    "#node_size = [d[1]*10000 for d in nx.eigenvector_centrality(g).items()]\n",
    "node_size = [n[1]['betweenness']*500000+20 for n in g.nodes.data()]\n",
    "#print(node_size)\n",
    "\n",
    "\n",
    "\n",
    "## label only for the 10 most relevant intermediaries\n",
    "node_labels =  dict(((u), \n",
    "                    str(d['label']))\n",
    "                    if d['betweenness'] > b \n",
    "                    else ((u), \n",
    "                    str(''))\n",
    "                    for u, d in g.nodes(data=True))\n",
    "#print(node_labels)\n",
    "\n",
    "node_colors = 'blue'\n",
    "\n",
    "### On représente successivement les différentes sommets et arêtes,\n",
    "# puis on ajoute les labels\n",
    "nx.draw_networkx_nodes(g, pos,  node_color=node_colors, node_size=node_size, alpha=0.2)\n",
    "nx.draw_networkx_edges(g, pos, alpha=0.02) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, alpha=0.8, font_size=20)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=50)\n",
    "plt.savefig('images/biggest_sliced_education_relationships_component_1901_1920.svg')\n",
    "plt.close()\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Egograph based on eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei = sorted([n[1]['eigenvector'] for n in big_ppG.nodes.data()], reverse=True)[10]\n",
    "print(ei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = [n[0] for n in big_ppG.nodes.data() if n[1]['eigenvector'] >= ei ]\n",
    "print(len(ln), ln[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_graph = nx.ego_graph(big_ppG, ln[1], radius=2)\n",
    "egn = list(ego_graph.nodes())\n",
    "print(egn[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display variable\n",
    "\n",
    "egos_graph = nx.Graph()\n",
    "\n",
    "l_nodes=[]\n",
    "i = 0\n",
    "while i < len(ln):\n",
    "    ego_graph = nx.ego_graph(big_ppG, ln[1], radius=3)\n",
    "    egn = list(ego_graph.nodes())\n",
    "    l_nodes += egn\n",
    "    i += 1\n",
    "\n",
    "egos_graph = nx.subgraph(big_ppG, l_nodes)\n",
    "\n",
    "naf.basic_graph_properties(egos_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(list(egos_graph.nodes.data())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei2 = sorted([n[1]['eigenvector'] for n in big_ppG.nodes.data()], reverse=True)[50]\n",
    "print(ei2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "g = egos_graph\n",
    "\n",
    "n_size = np.log(np.sqrt(nx.number_of_nodes(g)))* 20 #*25\n",
    "\n",
    "graph_layout = 'spring_layout'\n",
    "n_k = 0.7\n",
    "sc = 0.05\n",
    "\n",
    "### Define the layout, i.e. the choice \n",
    "# of the algorithm for the representation of the graph.\n",
    "\n",
    "if graph_layout == 'fruchterman_reingold':\n",
    "    pos = nx.fruchterman_reingold_layout(g)\n",
    "elif graph_layout == 'kamada_kawai':\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "elif graph_layout == 'spring_layout':\n",
    "    pos = nx.spring_layout(g, k = n_k, scale=sc)  \n",
    "else:\n",
    "    pos = nx.kamada_kawai_layout(g)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://networkx.org/documentation/stable/reference/drawing.html\n",
    "plt.figure(figsize = (n_size,n_size))\n",
    "\n",
    "\n",
    "\n",
    "## on définit ici l'algorythme avec lequel le traphe sera représenté\n",
    "\n",
    "# node_size = [d[1]*100 for d in nx.degree(g)]\n",
    "#node_size = [d[1]*10000 for d in nx.eigenvector_centrality(g).items()]\n",
    "node_size = [n[1]['eigenvector']*50000+20 for n in g.nodes.data()]\n",
    "#print(node_size)\n",
    "\n",
    "\n",
    "\n",
    "## label only for the 10 most relevant intermediaries\n",
    "node_labels =  dict(((u), \n",
    "                    str(d['label']))\n",
    "                    if d['eigenvector'] >= ei2\n",
    "                    else ((u), \n",
    "                    str(''))\n",
    "                    for u, d in g.nodes(data=True))\n",
    "#print(node_labels)\n",
    "\n",
    "node_colors = 'blue'\n",
    "\n",
    "### On représente successivement les différentes sommets et arêtes,\n",
    "# puis on ajoute les labels\n",
    "nx.draw_networkx_nodes(g, pos,  node_color=node_colors, node_size=node_size, alpha=0.2)\n",
    "nx.draw_networkx_edges(g, pos, alpha=0.02) # edgelist=ln, edge_color=c, \n",
    "nx.draw_networkx_labels(g, pos, labels=node_labels, alpha=0.8, font_size=20)\n",
    "\n",
    "### On peut augmenter ou diminuer ce paramètre pour ajuster le graphe\n",
    "plt.tight_layout(pad=50)\n",
    "plt.savefig('images/biggest_egos_education_relationships_component_1901_1920.svg')\n",
    "plt.close()\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export node attributes to dataframe\n",
    "nodes_data ={node: egos_graph.nodes[node] for node in egos_graph.nodes}\n",
    "nodes_df = pd.DataFrame(nodes_data).T\n",
    "nodes_df.reset_index(inplace=True)\n",
    "nodes_df.columns = ['personUri', 'label', 'birthYear','degree','eigenvector', 'betweenness']\n",
    "nodes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "exp = nodes_df.sort_values(by='betweenness', ascending=False).iloc[:100]\n",
    "\n",
    "### Adapt image size and police\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "plt.scatter(exp['eigenvector'],\n",
    "           exp['betweenness'],\n",
    "            marker='o',\n",
    "           color='DarkCyan'\n",
    "           )\n",
    "plt.xlabel('eigenvector')\n",
    "plt.ylabel('betweenness')\n",
    "\n",
    "for i,row in list(exp[['label','eigenvector', 'betweenness']].iterrows()):\n",
    "    plt.annotate(row['label'],( row['eigenvector'],row['betweenness']),\n",
    "                 fontsize=7)\n",
    "#plt.legend(title='Node type')\n",
    "#plt.savefig('plots/sieges_eigenvector_20210526.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_high_egv = nodes_df['personUri'][nodes_df.eigenvector> ei2].to_list()\n",
    "print(len(persons_high_egv), persons_high_egv[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecting_orgs = gr_mer[(gr_mer.uriPer_x.isin(persons_high_egv))|(gr_mer.uriPer_y.isin(persons_high_egv))].groupby(by='orgs').size()\n",
    "# file_add='data/connecting_orgs.csv'\n",
    "# connecting_orgs.sort_values(ascending=False).to_csv(file_add)\n",
    "print(connecting_orgs.sort_values(ascending=False).iloc[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_data_analysis",
   "language": "python",
   "name": "py311_data_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
